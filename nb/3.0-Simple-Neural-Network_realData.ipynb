{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Bucketing\n",
    "\n",
    "In this notebook we'll train a simple feed forward neural network (multilayer perceptron) to bucket customers into customer cohorts defined by product interest and demographic information.\n",
    "\n",
    "First, some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# interactive plotting by Bokeh\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook, push_notebook\n",
    "\n",
    "# pretty progress by tqdm\n",
    "from tqdm import tnrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use PyViz's [Bokeh](https://bokeh.pydata.org/en/latest/) to build interactive plots in this notebook. Bokeh uses a js kernel to serve data to screen, so we need to initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Clean Data\n",
    "\n",
    "Next, we'll use PyData's [Pandas](https://pandas.pydata.org/) to load in a `.csv` file of customers, their purchases, and a small amount of demographic information about them. We'll then split the resulting dataframe into three arrays:\n",
    "\n",
    "1. A *[samples x 1]* vector of customer UUIDs.\n",
    "\n",
    "2. A *[samples x 1]* vector of customer cohort buckets. These are our \"labels\" for training our model.\n",
    "\n",
    "3. A *[samples x features]* matrix of feature vectors. The first columns are number of items purchased by each customer, and the last columns are the demographic information we have about the customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in .csv file as a Pandas DataFrame\n",
    "customers = pd.read_csv('../dat/feature_vectors.csv')\n",
    "\n",
    "# output number of customers and calculated number of buckets\n",
    "num_cust = customers.shape[0]\n",
    "num_bkts = customers['KMeanGrouping'].unique().shape[0]\n",
    "\n",
    "print('number of customers:', num_cust)\n",
    "print('number of customer buckets:', num_bkts)\n",
    "\n",
    "# split off customer UUIDs\n",
    "uuids = customers['CustomerID']\n",
    "# split off bucket labels for training\n",
    "buckets = customers['KMeanGrouping']\n",
    "# relabel buckets in the range [0-30], since there are missing integers in the file\n",
    "buckets.replace(to_replace=buckets.unique(), value=range(buckets.unique().shape[0]), inplace=True)\n",
    "# drop the labels and the UUIDs from the feature vectors\n",
    "customers.drop(['CustomerID','KMeanGrouping'], axis=1, inplace=True)\n",
    "\n",
    "# calculate number of features\n",
    "num_ftrs = customers.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build neural network\n",
    "\n",
    "This model is slightly different from the one in the regression task of notebook `2.0-Simple-Neural-Network.ipynb` for two reasons:\n",
    "\n",
    "1. The input and output of this network has mulitiple features, defined by `input_size` and `num_classes`. This is because we have a multifeature input, or \"feature vector.\" In the regression task, we input one value, and expected one output value. In this task, we input as many values as we have products and demographic info. \n",
    "\n",
    "2. The output of the model is a 30 element vector which represents the probability of the input sample corresponding to each of the 30 \"classes,\" or buckets. The `nn.Softmax` layer on the back of the model calculates these probabilities. Instead of \"regressing\" one input x value to one output y value, we \"classify\" one feature vector to one class.\n",
    "\n",
    "We've also included a set of commented out layers. By adding these layers back in at home, you'll add more depth to your network, and increase the accuracy of your predictions. The cost of calculating and backpropagating gradients increases dramatically, so don't expect to be able to train it in an hour on a single thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(FirstNet, self).__init__()\n",
    "        self.fc1  = nn.Linear(input_size, 3000)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #self.fc2  = nn.Linear(3000, 2000)\n",
    "        #self.relu2 = nn.ReLU()\n",
    "        #self.fc3  = nn.Linear(2000, 1000)\n",
    "        #self.relu3 = nn.ReLU()\n",
    "        self.fc4  = nn.Linear(3000, num_classes)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        #out = self.fc2(out)\n",
    "        #out = self.relu2(out)\n",
    "        #out = self.fc3(out)\n",
    "        #out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.soft(out)\n",
    "        return out\n",
    "    \n",
    "net = FirstNet(input_size=num_ftrs, num_classes=num_bkts)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "Below, we'll run the data through the untrained model to see what the output looks like. First we check for a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = customers.as_matrix()\n",
    "X = torch.FloatTensor(X)\n",
    "X = Variable(X)\n",
    "\n",
    "if use_cuda:\n",
    "    Y = net.forward(X.cuda()).cpu()\n",
    "else:\n",
    "    Y = net.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the output from the untrained model against the groundtruth. You can click the labels in the legend to turn off the predictions or the true class values. If you click the mouse wheel control on the right side of the diagram, you can zoom and pan simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the plot\n",
    "p1 = figure(plot_width=900, plot_height=500, title=\"Customer Cohort Buckets\")\n",
    "p1.title.text_font_size = '24pt'\n",
    "p1.xaxis.axis_label = 'Customer UUID'\n",
    "p1.yaxis.axis_label = 'Cohort #'\n",
    "\n",
    "# plot the cohort bucket data\n",
    "r1 = p1.circle(uuids, buckets, fill_alpha=0.6, line_alpha=0.6, legend='groundtruth')\n",
    "# plot the predictions from the network\n",
    "r2 = p1.circle(uuids, np.argmax(Y.data, axis=1), fill_alpha=0.2, line_alpha=0.2, \n",
    "               fill_color='red', line_color='red', legend='prediction')\n",
    "\n",
    "# set up the legend\n",
    "p1.legend.location = \"top_left\"\n",
    "p1.legend.click_policy=\"hide\"\n",
    "\n",
    "# show the plot inline\n",
    "show(p1, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "Now let's train the model. Even the tiny neural network we defined above will take longer than we have time to train during this class, but let's kick it off, watch the loss, and see if it's learning anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# format the labels as PyTorch variables\n",
    "Y = buckets.as_matrix()\n",
    "Y = Variable(torch.LongTensor(Y))\n",
    "\n",
    "# define hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2000\n",
    "loss_hist = []\n",
    "\n",
    "# build a multiclass cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# instantiate a stochastic gradient descent optimizer class\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "# set the model parameters for training mode\n",
    "net.train()\n",
    "\n",
    "# build a loss plot\n",
    "p2 = figure(plot_width=900, plot_height=500)\n",
    "r2 = p2.line(range(len(loss_hist)), loss_hist)\n",
    "p2.legend.location = \"top_left\"\n",
    "p2.legend.click_policy=\"hide\"\n",
    "loss_plot = show(p2, notebook_handle=True)\n",
    "\n",
    "# send data to GPU, if appropriate\n",
    "if use_cuda:\n",
    "    criterion = criterion.cuda()\n",
    "    X = X.cuda()\n",
    "    Y = Y.cuda()\n",
    "\n",
    "# train for many epochs\n",
    "for epoch in tnrange(num_epochs):\n",
    "    # forward pass through the model\n",
    "    pred = net.forward(X)\n",
    "    # calculate local value on the loss surface\n",
    "    loss = criterion(pred, Y)\n",
    "\n",
    "    # clear the gradient buffer\n",
    "    optimizer.zero_grad()\n",
    "    # backward pass through the model to calculate gradients\n",
    "    loss.backward()\n",
    "    # take one step towards a minimum in the loss surface\n",
    "    optimizer.step()\n",
    "\n",
    "    # replot the network loss for one epoch\n",
    "    loss_hist.append(loss.data[0])\n",
    "    r2 = p2.line(range(len(loss_hist)), loss_hist)\n",
    "    push_notebook(handle=loss_plot)\n",
    "    \n",
    "# set the model parameters for inference mode\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Trained Model\n",
    "\n",
    "Always (always!) save your trained model weights. You'll thank yourself laters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('loss.npy', np.array(loss_hist), allow_pickle=False)\n",
    "\n",
    "torch.save(net.cpu().state_dict(), 'firstnet.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
